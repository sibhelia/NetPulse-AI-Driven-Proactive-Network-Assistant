from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import psycopg2
import pandas as pd
import joblib
import os
import random
import time
import logging
from datetime import datetime
import llm_service, sms_sender
from lstm_service import (
    LSTMPredictionService,
    HybridEnsembleModel,
    PredictionResult
)
from status_tracker import StatusTracker
from background_monitor import BackgroundMonitor

logger = logging.getLogger(__name__)

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
MODEL_PATH = os.path.join(BASE_DIR, 'saved_models', 'netpulse_classifier.pkl')

# LSTM Model Paths
LSTM_MODEL_PATH = os.path.join(BASE_DIR, 'saved_models', 'netpulse_lstm.h5')
LSTM_SCALER_PATH = os.path.join(BASE_DIR, 'saved_models', 'lstm_scaler.pkl')
LSTM_ENCODER_PATH = os.path.join(BASE_DIR, 'saved_models', 'lstm_encoder.pkl')

DB_CONFIG = {
    "dbname": "netpulse_db",
    "user": "postgres",
    "password": "admin",
    "host": "localhost",
    "port": "5432"
}

# Load Random Forest Model
model = None
try:
    model = joblib.load(MODEL_PATH)
    logger.info("âœ… Random Forest model loaded")
except Exception as e:
    logger.warning(f"âš ï¸ Random Forest load failed: {e}")

# Initialize LSTM Service
lstm_service = LSTMPredictionService(
    LSTM_MODEL_PATH, LSTM_SCALER_PATH, LSTM_ENCODER_PATH
)

# Initialize Hybrid Ensemble Model
hybrid_model = HybridEnsembleModel(rf_weight=0.6, lstm_weight=0.4)

# Background Monitor (initialized at startup)
background_monitor = None

def get_db_connection():
    try:
        return psycopg2.connect(**DB_CONFIG)
    except:
        return None

# --- YARDIMCI FONKSÄ°YONLAR ---

def generate_fault_scenario(scenario_type):
    """ArÄ±za tÃ¼rÃ¼ne gÃ¶re mantÄ±klÄ± bir SEBEP, AKSÄ°YON ve SÃœRE Ã¼retir."""
    if scenario_type == "ping":
        return {"cause": "BÃ¶lgesel veri trafiÄŸi yoÄŸunluÄŸu", "action": "YÃ¼k dengeleme aktif edildi", "eta": "30 dk"}
    elif scenario_type == "speed":
        return {"cause": "Ana fiber omurgada sinyal zayÄ±flamasÄ±", "action": "Santral optimizasyonu baÅŸlatÄ±ldÄ±", "eta": "1 saat"}
    elif scenario_type == "loss":
        return {"cause": "Saha dolabÄ±nda donanÄ±m arÄ±zasÄ±", "action": "Saha ekibi yÃ¶nlendirildi", "eta": "3 saat"}
    else:
        return {"cause": "PlanlÄ± bakÄ±m Ã§alÄ±ÅŸmasÄ±", "action": "Sistem gÃ¼ncelleniyor", "eta": "15 dk"}

def simulate_metrics_single(plan, force_trouble=False):
    """Tekil kullanÄ±cÄ± iÃ§in detaylÄ± simÃ¼lasyon (Eski fonksiyonumuz)"""
    is_problem = random.random() < 0.2 or force_trouble
    
    metrics = {
        "latency": random.uniform(10, 50),
        "packet_loss": random.uniform(0, 0.05),
        "jitter": random.uniform(1, 10),
        "download_speed": 100.0,
        "upload_speed": 20.0,
        "signal_strength": random.uniform(-60, -30),
        "connected_devices": random.randint(1, 10)
    }
    
    fault_details = None

    if "1000" in plan: metrics["download_speed"] = random.uniform(800, 1000)
    elif "100" in plan: metrics["download_speed"] = random.uniform(80, 100)
    else: metrics["download_speed"] = random.uniform(20, 50)

    if is_problem:
        scenario_type = random.choice(["ping", "speed", "loss"])
        if force_trouble: scenario_type = "loss"
        
        if scenario_type == "ping":
            metrics["latency"] = random.uniform(150, 400)
            metrics["jitter"] = random.uniform(50, 150)
        elif scenario_type == "speed":
            metrics["download_speed"] = random.uniform(1, 10)
        elif scenario_type == "loss":
            metrics["packet_loss"] = random.uniform(10, 40)
            metrics["signal_strength"] = random.uniform(-90, -80)
            
        fault_details = generate_fault_scenario(scenario_type)

    return metrics, fault_details, is_problem

# --- YENÄ° EKLENEN KISIM: TRAFFIC LIGHT SEGMENTASYONU ---

def classify_subscriber_status(metrics, ai_prediction):
    """
    Traffic Light AlgoritmasÄ±:
    Ham verileri ve AI tahminini birleÅŸtirip RENK kararÄ± verir.
    """
    # 1. KÄ±rmÄ±zÄ± KuralÄ± (Kritik)
    if ai_prediction in [2, 3] or metrics['packet_loss'] > 5 or metrics['download_speed'] < 5:
        return "RED"
    
    # 2. SarÄ± KuralÄ± (Riskli / Warning)
    # AI 'Normal' dese bile Ping yÃ¼ksekse veya HÄ±z dalgalÄ±ysa SARI yak.
    # Bu, "Kestirimci BakÄ±m" (Predictive) Ã¶zelliÄŸidir.
    if metrics['latency'] > 80 or metrics['jitter'] > 30 or ai_prediction == 1:
        return "YELLOW"
    
    # 3. YeÅŸil KuralÄ± (Normal)
    return "GREEN"

@app.get("/")
def home():
    return {
        "status": "active", 
        "mode": "Enterprise NOC",
        "lstm_available": lstm_service.is_available
    }

from pydantic import BaseModel
from typing import List, Optional

# --- Pydantic Models ---
class TicketRequest(BaseModel):
    subscriber_id: int
    technician_id: int
    issue_type: str
    notes: str

# --- YARDIMCI ENDPOINTLER ---

@app.get("/api/technicians")
def get_technicians():
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("SELECT id, name, expertise, status FROM technicians")
    techs = cursor.fetchall()
    conn.close()
    return [{"id": t[0], "name": t[1], "expertise": t[2], "status": t[3]} for t in techs]

@app.post("/api/tickets")
def create_ticket(ticket: TicketRequest):
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("""
        INSERT INTO tickets (subscriber_id, technician_id, issue_type, status, notes)
        VALUES (%s, %s, %s, 'Open', %s) RETURNING ticket_id
    """, (ticket.subscriber_id, ticket.technician_id, ticket.issue_type, ticket.notes))
    new_id = cursor.fetchone()[0]
    conn.commit()
    conn.close()
    return {"ticket_id": new_id, "status": "Created"}

@app.post("/api/actions/{action_type}")
def perform_action(action_type: str, subscriber_id: int = 0):
    # Simulate action
    time.sleep(1) # Fake delay
    return {"status": "Success", "message": f"{action_type} iÅŸlemi baÅŸarÄ±yla tamamlandÄ±."}

# --- 1. ENDPOINT: TEKÄ°L ANALÄ°Z (GeliÅŸmiÅŸ) ---
@app.get("/api/simulate/{subscriber_id}")
def simulate_network(subscriber_id: int, force_trouble: bool = False):
    conn = get_db_connection()
    if not conn: raise HTTPException(status_code=500, detail="Database fail")
    
    cursor = conn.cursor()
    # Fetch extended info
    cursor.execute("""
        SELECT full_name, subscription_plan, region_id, gender, phone_number, modem_model, ip_address, uptime 
        FROM customers WHERE subscriber_id = %s
    """, (subscriber_id,))
    customer = cursor.fetchone()
    
    if not customer: 
        conn.close()
        raise HTTPException(status_code=404, detail="User not found")

    name, plan, region, gender, phone, modem, ip, uptime = customer
    
    # Generate unique location based on subscriber_id  
    # Ä°stanbul bÃ¶lgeleri iÃ§in yaklaÅŸÄ±k koordinatlar
    region_coords = {
        "KadÄ±kÃ¶y": (40.99, 29.03),
        "BeÅŸiktaÅŸ": (41.04, 29.00),
        "ÃœskÃ¼dar": (41.02, 29.01),
        "ÅiÅŸli": (41.06, 28.99),
        "BakÄ±rkÃ¶y": (40.98, 28.87)
    }
    
    base_region = region.split('/')[0]  # "KadÄ±kÃ¶y/Moda" -> "KadÄ±kÃ¶y"
    base_lat, base_lon = region_coords.get(base_region, (41.01, 28.98))
    
    # Her abone iÃ§in benzersiz offset (subscriber_id'ye gÃ¶re deterministic)
    import hashlib
    hash_val = int(hashlib.md5(str(subscriber_id).encode()).hexdigest(), 16)
    lat_offset = (hash_val % 100) / 10000.0  # 0.0000-0.0099 arasÄ±
    lon_offset = ((hash_val // 100) % 100) / 10000.0
    
    subscriber_lat = base_lat + lat_offset - 0.005  # Merkezden sapma
    subscriber_lon = base_lon + lon_offset - 0.005
    
    # Rastgele sokak adÄ± (subscriber_id'ye gÃ¶re deterministic)
    street_names = ["BaÄŸdat Caddesi", "Nispetiye Caddesi", "AcÄ±badem Caddesi", 
                    "TeÅŸvikiye Caddesi", "AtatÃ¼rk Caddesi", "Cumhuriyet Caddesi",
                    "Ä°stiklal Caddesi", "Bahariye Caddesi", "Moda Caddesi"]
    street_index = subscriber_id % len(street_names)
    building_no = (subscriber_id % 200) + 1
    location_address = f"{street_names[street_index]} No:{building_no}, {region}"
    
    # Fetch Recent Tickets
    cursor.execute("""
        SELECT t.created_at, t.issue_type, t.status, tech.name 
        FROM tickets t 
        LEFT JOIN technicians tech ON t.technician_id = tech.id
        WHERE t.subscriber_id = %s 
        ORDER BY t.created_at DESC LIMIT 5
    """, (subscriber_id,))
    history = cursor.fetchall()
    
    # Analyze Region Status (For Storytelling)
    # Count faulty users in same region
    cursor.execute("""
        SELECT COUNT(*) FROM customers c
        JOIN subscriber_status ss ON c.subscriber_id = ss.subscriber_id
        WHERE c.region_id = %s AND ss.current_status IN ('RED', 'YELLOW')
    """, (region,))
    region_fault_count = cursor.fetchone()[0]
    
    # Simulate Live Metrics
    # [NEW] SYNC WITH DB STATUS
    # List sayfasÄ±nda ne gÃ¶rÃ¼nÃ¼yorsa detayda da o gÃ¶rÃ¼nmeli.
    cursor.execute("SELECT current_status FROM subscriber_status WHERE subscriber_id = %s", (subscriber_id,))
    row = cursor.fetchone()
    db_status = row[0] if row else None
    
    conn.close()

    # EÄŸer DB'de bir sorun kaydÄ± varsa, simÃ¼lasyonu ona gÃ¶re zorla
    force_metrics_state = None
    if db_status == "RED" or db_status == "YELLOW":
        force_metrics_state = db_status

    live_data, fault_details, is_faulty = simulate_metrics_single(plan, force_trouble=(force_trouble or force_metrics_state is not None))
    
    # Override metrics if specific state needed to match DB
    if force_metrics_state == "RED":
        live_data["packet_loss"] = random.uniform(15, 40)
        live_data["download_speed"] = random.uniform(0.1, 3.0)
    elif force_metrics_state == "YELLOW":
        live_data["latency"] = random.uniform(90, 250)
        live_data["jitter"] = random.uniform(30, 80)
    
    # ... (Rest of AI logic same as before, condensed for brevity) ...
    # Re-implementing simplified AI logic just for this response to ensure flow consistency
    # In real file, we would keep the existing LSTM/RF logic. 
    # Since I'm replacing the whole function block, I need to include it or reference it.
    
    # Let's re-use the existing global objects: lstm_service, model, hybrid_model
    
    # 1. LSTM
    lstm_result = None
    if lstm_service and lstm_service.is_available:
        lstm_service.add_measurement(subscriber_id, live_data)
        lstm_result = lstm_service.predict(subscriber_id)
        
    # 2. RF
    prediction_code = 0
    rf_confidence = 0.5
    try:
        prediction_code = int(model.predict(pd.DataFrame([live_data]))[0]) if model else 0
    except: pass
    
    rf_result = PredictionResult("RandomForest", prediction_code, rf_confidence, [], datetime.now())
    
    # 3. Hybrid
    final_risk, segment_color, ensemble_reason = hybrid_model.combine_predictions(rf_result, lstm_result) if hybrid_model else (0, "GREEN", "System Log")
    
    # [KRITIK] Status Persistence - Prevent rapid status flipping
    # Use StatusTracker to enforce minimum durations (RED=10min, YELLOW=5min)
    try:
        tracker = StatusTracker(conn)
        
        # Check if we're allowed to change to the AI-predicted status
        permission = tracker.should_allow_status_change(subscriber_id, segment_color)
        
        if not permission["allowed"]:
            # Status change blocked - keep old status
            logger.info(f"â¸ï¸ Status change blocked for {subscriber_id}: {permission['reason']}")
            # DB status varsa onu kullan, yoksa GREEN
            segment_color = db_status if db_status else "GREEN"
            ensemble_reason = f"Status locked: {permission['reason']}"
        elif db_status and db_status != segment_color:
            # Status change allowed and different from DB - update via tracker
            logger.info(f"âœ… Status change allowed for {subscriber_id}: {db_status} â†’ {segment_color}")
            tracker.update_status(subscriber_id, segment_color, fault_type="network_degradation")
        elif not db_status:
            # First time - initialize status
            tracker.update_status(subscriber_id, segment_color)
    except Exception as e:
        logger.error(f"âŒ StatusTracker error for {subscriber_id}: {e}")
        # Fallback to old behavior
        if db_status and db_status in ["RED", "YELLOW", "GREEN"]:
            segment_color = db_status
            ensemble_reason = f"DB synchronized status ({db_status})"

    
    # --- DETAILED NARRATIVE ANALYSIS ---
    analysis_story = ""
    estimated_fix = "Belirsiz"
    
    if segment_color == "GREEN":
        analysis_story = f"{region} bÃ¶lgesindeki altyapÄ± analiz edildi ve tÃ¼m parametreler normal aralÄ±kta tespit edildi. HattÄ±nÄ±zda herhangi bir fiziksel veya yazÄ±lÄ±msal sorun bulunmamaktadÄ±r. LSTM trend analizi ve Random Forest sÄ±nÄ±flandÄ±rma modelleri de baÄŸlantÄ±nÄ±zÄ±n stabil olduÄŸunu doÄŸruluyor. Sistem sÃ¼rekli izleme altÄ±ndadÄ±r."
        estimated_fix = "Gerekli deÄŸil"
    else:
        # Story logic
        if region_fault_count > 5:
            analysis_story = f"{region} bÃ¶lgesinde kritik seviyede altyapÄ± sorunu tespit edildi. Sorun sadece sizin hattÄ±nÄ±zda deÄŸil, bÃ¶lge genelindeki {region_fault_count} aboneyi etkiliyor. Analiz sonuÃ§larÄ± ana daÄŸÄ±tÄ±m noktasÄ±nda (MDF/ODF) fiziksel veya konfigÃ¼rasyon problemi olduÄŸunu gÃ¶steriyor. Saha ekiplerimiz acil mÃ¼dahale iÃ§in gÃ¶revlendirilmiÅŸtir. Fiber altyapÄ± testi ve daÄŸÄ±tÄ±m noktasÄ± kontrolÃ¼ yapÄ±lacaktÄ±r. Bu tÃ¼r bÃ¶lgesel arÄ±zalar genellikle 2-4 saat iÃ§inde Ã§Ã¶zÃ¼lmektedir."
            estimated_fix = "2-4 Saat"
        else:
            # Determine specific issue type
            issue_type = "yÃ¼ksek gecikme (latency)" if live_data['latency'] > 50 else "paket kaybÄ±"
            issue_value = f"{live_data['latency']:.0f} ms" if live_data['latency'] > 50 else f"%{live_data.get('packet_loss', 0):.1f}"
            
            analysis_story = f"{region} bÃ¶lgesinde yaygÄ±n bir sorun tespit edilmedi. Modem ({modem}, IP: {ip}) ile santral arasÄ±ndaki sinyal kalitesinde degradasyon gÃ¶rÃ¼lmektedir. Hat deÄŸerlerinizde anlÄ±k {issue_type} ({issue_value}) Ã¶lÃ§Ã¼lmÃ¼ÅŸtÃ¼r. BÃ¶lgede baÅŸka abone etkilenmediÄŸinden, problem mÃ¼ÅŸteri lokasyonu ile sÄ±nÄ±rlÄ±dÄ±r. Saha teknisyeni gÃ¶ndererek iÃ§ tesisat kontrolÃ¼ ve modem sinyal seviyesi Ã¶lÃ§Ã¼mÃ¼ yaptÄ±rmanÄ±zÄ± Ã¶neriyoruz. Gerekirse ekipman deÄŸiÅŸimi planlanabilir. Bu tÃ¼r tekil hat arÄ±zalarÄ±nÄ±n Ã§Ã¶zÃ¼mÃ¼ ortalama 45 dakika sÃ¼rmektedir."
            estimated_fix = "45 Dakika"


    sms_info = {"sent": False, "message": None}

    return {
        "subscriber_id": subscriber_id,
        "customer_info": {
            "name": name, "plan": plan, "region": region, "phone": phone,
            "modem": modem, "ip": ip, "uptime": uptime, "gender": gender,
            "location": {
                "latitude": subscriber_lat,
                "longitude": subscriber_lon,
                "address": location_address
            }
        },
        "live_metrics": live_data,
        "ai_analysis": {
            "segment": segment_color,
            "risk_score": final_risk,
            "reason": ensemble_reason,
            "story": analysis_story,
            "estimated_fix": estimated_fix
        },
        "history": [
            {"date": h[0].strftime("%d.%m.%Y %H:%M"), "event": h[1], "status": h[2], "tech": h[3]} 
            for h in history
        ],
        "sms_notification": sms_info
    }

# --- 2. ENDPOINT: TOPLU TARAMA (Dashboard Ä°Ã§in) ---
@app.get("/api/scan_network")
def scan_network_batch():
    """
    TÃ¼m aboneleri (veya ilk 500'Ã¼) tarar, anlÄ±k durumlarÄ±nÄ± simÃ¼le eder 
    ve gruplandÄ±rÄ±r.
    """
    conn = get_db_connection()
    if not conn: raise HTTPException(status_code=500, detail="Database fail")
    
    cursor = conn.cursor()
    # Performans iÃ§in sadece gerekli kolonlarÄ± Ã§ekiyoruz
    cursor.execute("SELECT subscriber_id, full_name, subscription_plan, region_id FROM customers LIMIT 500")
    customers = cursor.fetchall()
    
    results = {
        "total": len(customers),
        "counts": {"GREEN": 0, "YELLOW": 0, "RED": 0},
        "lists": {"GREEN": [], "YELLOW": [], "RED": []}
    }
    
    # Toplu SimÃ¼lasyon DÃ¶ngÃ¼sÃ¼
    for cust in customers:
        sub_id, name, plan, region = cust
        
        # GerÃ§ekÃ§i DaÄŸÄ±lÄ±m Ä°Ã§in Zar AtÄ±yoruz:
        # Persistence (10dk) olduÄŸu iÃ§in Ã§ok dÃ¼ÅŸÃ¼k olasÄ±lÄ±klar kullanÄ±yoruz
        # Hedef: 500 kiÅŸide anlÄ±k ~5-10 RED, ~15-20 YELLOW
        rand_val = random.uniform(0, 100)
        
        # HÄ±zlÄ± simÃ¼lasyon (Tekil fonksiyondan daha basit veriler)
        metrics = {
            "latency": random.uniform(10, 40),
            "packet_loss": 0,
            "download_speed": 100,
            "jitter": random.uniform(1, 5)
        }
        
        ai_pred = 0
        
        
        
        # KÄ±rmÄ±zÄ± Durumu SimÃ¼le Et (%0.05 OlasÄ±lÄ±k -> Her 2000 taramada 1)
        # Hedef: Peak Hour simÃ¼lasyonunu (25 RED) canlÄ± tutmak
        if rand_val > 99.95:
            metrics["packet_loss"] = random.uniform(10, 30)
            metrics["download_speed"] = 2.0
            ai_pred = 2
        # SarÄ± Durumu SimÃ¼le Et (%0.3 OlasÄ±lÄ±k -> Her 333 taramada 1)
        # Hedef: Proaktif analiz (50 YELLOW) havuzunu beslemek
        elif rand_val > 99.7:
            metrics["latency"] = random.uniform(90, 180) # Ping yÃ¼kselmiÅŸ
            metrics["jitter"] = random.uniform(20, 50)
            ai_pred = 0 # AI henÃ¼z hata demiyor ama biz RISK gÃ¶rÃ¼yoruz
            
        # Segmentasyon Fonksiyonunu Ã‡aÄŸÄ±r
        proposed_color = classify_subscriber_status(metrics, ai_pred)
        
        # [PERSISTENCE] Status Tracker Entegrasyonu
        # Random Ã¼retim GREEN dese bile, eÄŸer DB'de RED varsa ve sÃ¼re dolmadÄ±ysa RED kalmalÄ±
        
        final_color = proposed_color
        try:
            tracker = StatusTracker(conn)
            permission = tracker.should_allow_status_change(sub_id, proposed_color)
            
            if permission["allowed"]:
                # DeÄŸiÅŸikliÄŸe izin var, yeni durumu kaydet
                if proposed_color != "GREEN": # Sadece sorunlarÄ± logla, performansÄ± koru
                    logger.info(f"âš¡ Batch Scan: Status change allowed for {sub_id}: â†’ {proposed_color}")
                
                tracker.update_status(sub_id, proposed_color)
                final_color = proposed_color
            else:
                # Ä°zin yok, mevcut durumu koru (DB'den ne geldiyse o)
                # Ancak DB statÃ¼sÃ¼nÃ¼ bilmiyoruz, sorgulamamÄ±z lazÄ±m
                current_status_info = tracker.get_current_status(sub_id)
                final_color = current_status_info["current"]
                # logger.info(f"ğŸ”’ Batch Scan: Status change blocked for {sub_id}: {permission['reason']}")

        except Exception as e:
            logger.error(f"Batch scan persistence error: {e}")
            # Hata durumunda proposed kullan
            final_color = proposed_color
            
        color = final_color

        # Ä°statistiklere Ekle
        results["counts"][color] += 1
        
        # Listeye Ekle (ARTIK TÃœM ABONELER EKLENÄ°YOR)
        issue_text = "Stabil"
        if color == "YELLOW": issue_text = "YÃ¼ksek Ping"
        elif color == "RED": issue_text = "BaÄŸlantÄ± Kopuk"
        
        results["lists"][color].append({
            "id": sub_id,
            "name": name,
            "region": region, 
            "plan": plan,
            "issue": issue_text,
            "metrics": metrics
        })
    
    conn.close()
    return results


# --- 3. ENDPOINT: LSTM TREND ANALÄ°ZÄ° (YENÄ°!) ---
@app.get("/api/trend/{subscriber_id}")
def get_trend_analysis(subscriber_id: int):
    """
    LSTM-based trend analysis for proactive monitoring
    Returns detailed risk forecast and trend direction
    """
    if not lstm_service.is_available:
        raise HTTPException(
            status_code=503, 
            detail="LSTM service unavailable. Model not loaded."
        )
    
    # Get trend analysis
    trend = lstm_service.analyze_trend(subscriber_id)
    
    if not trend:
        # Not enough data yet
        cache_size = len(lstm_service.measurement_cache.get(subscriber_id, []))
        raise HTTPException(
            status_code=400,
            detail=f"Not enough data for trend analysis. Have {cache_size}/12 measurements. Need 1 hour of data."
        )
    
    # Get customer info
    conn = get_db_connection()
    customer_name = "Unknown"
    if conn:
        cursor = conn.cursor()
        cursor.execute("SELECT full_name FROM customers WHERE subscriber_id = %s", (subscriber_id,))
        result = cursor.fetchone()
        if result:
            customer_name = result[0]
        conn.close()
    
    return {
        "subscriber_id": subscriber_id,
        "customer_name": customer_name,
        "analysis": {
            "current_risk": round(trend.current_risk, 3),
            "trend_direction": trend.trend_direction,
            "forecast_30min": round(trend.forecast_30min, 3),
            "risk_chart": [round(r, 3) for r in trend.risk_chart],
            "recommendation": trend.recommendation,
            "severity": "HIGH" if trend.forecast_30min > 0.7 else ("MEDIUM" if trend.forecast_30min > 0.4 else "LOW")
        },
        "metadata": {
            "measurements_count": len(trend.risk_chart),
            "window_size": lstm_service.window_size,
            "model_status": "active",
            "model_name": "LSTM"
        }
    }
# === STARTUP & SHUTDOWN EVENTS ===

@app.on_event("startup")
async def startup_event():
    """
    Backend baÅŸlangÄ±cÄ±nda:
    1. TÃ¼m 500 abone iÃ§in LSTM cache oluÅŸtur (12 Ã¶lÃ§Ã¼m)
    2. Otomatik periodic monitoring baÅŸlat (her 5 dakika)
    """
    global background_monitor
    
    logger.info("ğŸš€ NetPulse Backend baÅŸlatÄ±lÄ±yor...")
    
    if lstm_service and lstm_service.is_available:
        background_monitor = BackgroundMonitor(
            get_db_func=get_db_connection,
            lstm_service=lstm_service,
            simulate_func=simulate_metrics_single
        )
        
        await background_monitor.start()
        logger.info("âœ… Background monitoring aktif! (500 abone)")
    else:
        logger.warning("âš ï¸ LSTM unavailable, background monitoring disabled")


@app.on_event("shutdown")
async def shutdown_event():
    """Backend kapatÄ±lÄ±rken monitoring durdur"""
    if background_monitor:
        background_monitor.stop()
    logger.info("ğŸ‘‹ NetPulse Backend kapatÄ±ldÄ±")

# --- 3. ENDPOINT: ENHANCED TICKET NOTE GENERATION (LLM Style) ---
class TicketRequest(BaseModel):
    subscriber_id: int
    current_status: str
    ai_analysis: str

@app.post("/api/generate_ticket_note")
def generate_ticket_note(request: TicketRequest):
    """
    Generates a professional technician note based on subscriber status and regional context.
    Simulates an LLM response for speed and reliability.
    """
    try:
        conn = get_db_connection()
        if not conn:
            raise HTTPException(status_code=500, detail="Database fail")
        
        cursor = conn.cursor()
        
        # 1. Get detailed subscriber info
        cursor.execute("""
            SELECT region_id, modem_model 
            FROM customers WHERE subscriber_id = %s
        """, (request.subscriber_id,))
        cust_data = cursor.fetchone()
        
        if not cust_data:
             return {"note": "Subscriber not found.", "scope": "INDIVIDUAL"}
             
        region_id, modem_model = cust_data
        
        # 2. Analyze Regional Context (Is it a regional outage?)
        # Count other faulty subscribers in the same region
        cursor.execute("""
            SELECT COUNT(*) 
            FROM customers c
            JOIN subscriber_status s ON c.subscriber_id = s.subscriber_id
            WHERE c.region_id = %s 
              AND s.current_status IN ('RED', 'YELLOW')
              AND c.subscriber_id != %s
        """, (region_id, request.subscriber_id))
        
        neighbor_faults = cursor.fetchone()[0]
        
        # Determine Scope
        scope = "REGIONAL" if neighbor_faults > 3 else "INDIVIDUAL"
        scope_icon = "ğŸ¢" if scope == "REGIONAL" else "ğŸ "
        
        # 3. Generate Note based on Status and Scope
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
        
        note_parts = []
        note_parts.append(f"**Teknisyen Notu - {timestamp}**")
        note_parts.append(f"**ArÄ±za KapsamÄ±:** {scope_icon} {scope} ({neighbor_faults} komÅŸu etkilendi)")
        note_parts.append(f"**Cihaz:** {modem_model}")
        note_parts.append(f"**AI Analizi:** {request.ai_analysis}")
        
        if request.current_status == "RED":
            if scope == "REGIONAL":
                note_parts.append("\n**TeÅŸhis:** BÃ¶lgesel AltyapÄ± ArÄ±zasÄ± tespit edildi.")
                note_parts.append("**Ã–nerilen Ä°ÅŸlem:** {}. BÃ¶lge daÄŸÄ±tÄ±m switch'ini ve fiber hattÄ±nÄ± kontrol edin. BÃ¶lgesel sorun Ã§Ã¶zÃ¼lmeden eve ekip yÃ¶nlendirmeyin.".format(region_id))
            else:
                note_parts.append("\n**TeÅŸhis:** Ä°zole Kritik ArÄ±za.")
                note_parts.append("**Ã–nerilen Ä°ÅŸlem:** Adrese saha ekibi yÃ¶nlendirin. Bina giriÅŸi ve modem/ONT gÃ¼Ã§ deÄŸerlerini kontrol edin.")
                
        elif request.current_status == "YELLOW":
            note_parts.append("\n**TeÅŸhis:** Performans DÃ¼ÅŸÃ¼klÃ¼ÄŸÃ¼ / TÄ±kanÄ±klÄ±k.")
            note_parts.append("**Ã–nerilen Ä°ÅŸlem:** Uzaktan hat testi yapÄ±n. SNR marjlarÄ±nÄ± kontrol edin. Sorun genel ise Peak Hour takibi yapÄ±n.")
            
        else:
            note_parts.append("\n**TeÅŸhis:** Abone Ã§evrimiÃ§i ancak sorun bildiriyor.")
            note_parts.append("**Ã–nerilen Ä°ÅŸlem:** Åikayet detayÄ± iÃ§in mÃ¼ÅŸteriyle iletiÅŸime geÃ§in.")
            
        final_note = "\n".join(note_parts)
        
        conn.close()
        
        return {
            "scope": scope,
            "note": final_note,
            "neighbor_count": neighbor_faults
        }

    except Exception as e:
        logger.error(f"Ticket Generation Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))
