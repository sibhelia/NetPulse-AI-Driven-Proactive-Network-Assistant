from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import psycopg2
import pandas as pd
import joblib
import os
import random
import time
import logging
from datetime import datetime
import llm_service, sms_sender
from lstm_service import (
    LSTMPredictionService,
    HybridEnsembleModel,
    PredictionResult
)
from status_tracker import StatusTracker
from background_monitor import BackgroundMonitor

logger = logging.getLogger(__name__)

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
MODEL_PATH = os.path.join(BASE_DIR, 'saved_models', 'netpulse_classifier.pkl')

# LSTM Model Paths
LSTM_MODEL_PATH = os.path.join(BASE_DIR, 'saved_models', 'netpulse_lstm.h5')
LSTM_SCALER_PATH = os.path.join(BASE_DIR, 'saved_models', 'lstm_scaler.pkl')
LSTM_ENCODER_PATH = os.path.join(BASE_DIR, 'saved_models', 'lstm_encoder.pkl')

DB_CONFIG = {
    "dbname": "netpulse_db",
    "user": "postgres",
    "password": "admin",
    "host": "localhost",
    "port": "5432"
}

# Load Random Forest Model
model = None
try:
    model = joblib.load(MODEL_PATH)
    logger.info("âœ… Random Forest model loaded")
except Exception as e:
    logger.warning(f"âš ï¸ Random Forest load failed: {e}")

# Initialize LSTM Service
lstm_service = LSTMPredictionService(
    LSTM_MODEL_PATH, LSTM_SCALER_PATH, LSTM_ENCODER_PATH
)

# Initialize Hybrid Ensemble Model
hybrid_model = HybridEnsembleModel(rf_weight=0.6, lstm_weight=0.4)

# Background Monitor (initialized at startup)
background_monitor = None

def get_db_connection():
    try:
        return psycopg2.connect(**DB_CONFIG)
    except:
        return None

# --- YARDIMCI FONKSÄ°YONLAR ---

def generate_fault_scenario(scenario_type):
    """ArÄ±za tÃ¼rÃ¼ne gÃ¶re mantÄ±klÄ± bir SEBEP, AKSÄ°YON ve SÃœRE Ã¼retir."""
    if scenario_type == "ping":
        return {"cause": "BÃ¶lgesel veri trafiÄŸi yoÄŸunluÄŸu", "action": "YÃ¼k dengeleme aktif edildi", "eta": "30 dk"}
    elif scenario_type == "speed":
        return {"cause": "Ana fiber omurgada sinyal zayÄ±flamasÄ±", "action": "Santral optimizasyonu baÅŸlatÄ±ldÄ±", "eta": "1 saat"}
    elif scenario_type == "loss":
        return {"cause": "Saha dolabÄ±nda donanÄ±m arÄ±zasÄ±", "action": "Saha ekibi yÃ¶nlendirildi", "eta": "3 saat"}
    else:
        return {"cause": "PlanlÄ± bakÄ±m Ã§alÄ±ÅŸmasÄ±", "action": "Sistem gÃ¼ncelleniyor", "eta": "15 dk"}

def simulate_metrics_single(plan, force_trouble=False):
    """Tekil kullanÄ±cÄ± iÃ§in detaylÄ± simÃ¼lasyon (Eski fonksiyonumuz)"""
    is_problem = random.random() < 0.2 or force_trouble
    
    metrics = {
        "latency": random.uniform(10, 50),
        "packet_loss": random.uniform(0, 0.05),
        "jitter": random.uniform(1, 10),
        "download_speed": 100.0,
        "upload_speed": 20.0,
        "signal_strength": random.uniform(-60, -30),
        "connected_devices": random.randint(1, 10)
    }
    
    fault_details = None

    if "1000" in plan: metrics["download_speed"] = random.uniform(800, 1000)
    elif "100" in plan: metrics["download_speed"] = random.uniform(80, 100)
    else: metrics["download_speed"] = random.uniform(20, 50)

    if is_problem:
        scenario_type = random.choice(["ping", "speed", "loss"])
        if force_trouble: scenario_type = "loss"
        
        if scenario_type == "ping":
            metrics["latency"] = random.uniform(150, 400)
            metrics["jitter"] = random.uniform(50, 150)
        elif scenario_type == "speed":
            metrics["download_speed"] = random.uniform(1, 10)
        elif scenario_type == "loss":
            metrics["packet_loss"] = random.uniform(10, 40)
            metrics["signal_strength"] = random.uniform(-90, -80)
            
        fault_details = generate_fault_scenario(scenario_type)

    return metrics, fault_details, is_problem

# --- YENÄ° EKLENEN KISIM: TRAFFIC LIGHT SEGMENTASYONU ---

def classify_subscriber_status(metrics, ai_prediction):
    """
    Traffic Light AlgoritmasÄ±:
    Ham verileri ve AI tahminini birleÅŸtirip RENK kararÄ± verir.
    """
    # 1. KÄ±rmÄ±zÄ± KuralÄ± (Kritik)
    if ai_prediction in [2, 3] or metrics['packet_loss'] > 5 or metrics['download_speed'] < 5:
        return "RED"
    
    # 2. SarÄ± KuralÄ± (Riskli / Warning)
    # AI 'Normal' dese bile Ping yÃ¼ksekse veya HÄ±z dalgalÄ±ysa SARI yak.
    # Bu, "Kestirimci BakÄ±m" (Predictive) Ã¶zelliÄŸidir.
    if metrics['latency'] > 80 or metrics['jitter'] > 30 or ai_prediction == 1:
        return "YELLOW"
    
    # 3. YeÅŸil KuralÄ± (Normal)
    return "GREEN"

@app.get("/")
def home():
    return {
        "status": "active", 
        "mode": "Enterprise NOC",
        "lstm_available": lstm_service.is_available
    }

from pydantic import BaseModel
from typing import List, Optional

# --- Pydantic Models ---
class TicketRequest(BaseModel):
    subscriber_id: int
    technician_id: int
    issue_type: str
    notes: str

# --- YARDIMCI ENDPOINTLER ---

@app.get("/api/technicians")
def get_technicians():
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("SELECT id, name, expertise, status FROM technicians")
    techs = cursor.fetchall()
    conn.close()
    return [{"id": t[0], "name": t[1], "expertise": t[2], "status": t[3]} for t in techs]

@app.post("/api/tickets")
def create_ticket(ticket: TicketRequest):
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("""
        INSERT INTO tickets (subscriber_id, technician_id, issue_type, status, notes)
        VALUES (%s, %s, %s, 'Open', %s) RETURNING ticket_id
    """, (ticket.subscriber_id, ticket.technician_id, ticket.issue_type, ticket.notes))
    new_id = cursor.fetchone()[0]
    conn.commit()
    conn.close()
    return {"ticket_id": new_id, "status": "Created"}

@app.post("/api/actions/{action_type}")
def perform_action(action_type: str, subscriber_id: int = 0):
    # Simulate action
    time.sleep(1) # Fake delay
    return {"status": "Success", "message": f"{action_type} iÅŸlemi baÅŸarÄ±yla tamamlandÄ±."}

# --- 1. ENDPOINT: TEKÄ°L ANALÄ°Z (GeliÅŸmiÅŸ) ---
@app.get("/api/simulate/{subscriber_id}")
def simulate_network(subscriber_id: int, force_trouble: bool = False):
    conn = get_db_connection()
    if not conn: raise HTTPException(status_code=500, detail="Database fail")
    
    cursor = conn.cursor()
    # Fetch extended info
    cursor.execute("""
        SELECT full_name, subscription_plan, region_id, gender, phone_number, modem_model, ip_address, uptime 
        FROM customers WHERE subscriber_id = %s
    """, (subscriber_id,))
    customer = cursor.fetchone()
    
    if not customer: 
        conn.close()
        raise HTTPException(status_code=404, detail="User not found")

    name, plan, region, gender, phone, modem, ip, uptime = customer
    
    # Fetch Recent Tickets
    cursor.execute("""
        SELECT t.created_at, t.issue_type, t.status, tech.name 
        FROM tickets t 
        LEFT JOIN technicians tech ON t.technician_id = tech.id
        WHERE t.subscriber_id = %s 
        ORDER BY t.created_at DESC LIMIT 5
    """, (subscriber_id,))
    history = cursor.fetchall()
    
    # Analyze Region Status (For Storytelling)
    # Count faulty users in same region
    cursor.execute("""
        SELECT COUNT(*) FROM customers c
        JOIN subscriber_status ss ON c.subscriber_id = ss.subscriber_id
        WHERE c.region_id = %s AND ss.current_status IN ('RED', 'YELLOW')
    """, (region,))
    region_fault_count = cursor.fetchone()[0]
    
    # Simulate Live Metrics
    # [NEW] SYNC WITH DB STATUS
    # List sayfasÄ±nda ne gÃ¶rÃ¼nÃ¼yorsa detayda da o gÃ¶rÃ¼nmeli.
    cursor.execute("SELECT current_status FROM subscriber_status WHERE subscriber_id = %s", (subscriber_id,))
    row = cursor.fetchone()
    db_status = row[0] if row else None
    
    conn.close()

    # EÄŸer DB'de bir sorun kaydÄ± varsa, simÃ¼lasyonu ona gÃ¶re zorla
    force_metrics_state = None
    if db_status == "RED" or db_status == "YELLOW":
        force_metrics_state = db_status

    live_data, fault_details, is_faulty = simulate_metrics_single(plan, force_trouble=(force_trouble or force_metrics_state is not None))
    
    # Override metrics if specific state needed to match DB
    if force_metrics_state == "RED":
        live_data["packet_loss"] = random.uniform(15, 40)
        live_data["download_speed"] = random.uniform(0.1, 3.0)
    elif force_metrics_state == "YELLOW":
        live_data["latency"] = random.uniform(90, 250)
        live_data["jitter"] = random.uniform(30, 80)
    
    # ... (Rest of AI logic same as before, condensed for brevity) ...
    # Re-implementing simplified AI logic just for this response to ensure flow consistency
    # In real file, we would keep the existing LSTM/RF logic. 
    # Since I'm replacing the whole function block, I need to include it or reference it.
    
    # Let's re-use the existing global objects: lstm_service, model, hybrid_model
    
    # 1. LSTM
    lstm_result = None
    if lstm_service and lstm_service.is_available:
        lstm_service.add_measurement(subscriber_id, live_data)
        lstm_result = lstm_service.predict(subscriber_id)
        
    # 2. RF
    prediction_code = 0
    rf_confidence = 0.5
    try:
        prediction_code = int(model.predict(pd.DataFrame([live_data]))[0]) if model else 0
    except: pass
    
    rf_result = PredictionResult("RandomForest", prediction_code, rf_confidence, [], datetime.now())
    
    # 3. Hybrid
    final_risk, segment_color, ensemble_reason = hybrid_model.combine_predictions(rf_result, lstm_result) if hybrid_model else (0, "GREEN", "System Log")
    
    # [KRITIK] DB'de kayÄ±tlÄ± durum varsa onu kullan (Liste ile senkronize olmasÄ± iÃ§in)
    # Liste sayfasÄ±nda ne gÃ¶rÃ¼nÃ¼yorsa detayda da o gÃ¶rÃ¼nmeli
    if db_status and db_status in ["RED", "YELLOW", "GREEN"]:
        segment_color = db_status
        ensemble_reason = f"DB synchronized status ({db_status})"
    
    # --- DETAILED NARRATIVE ANALYSIS ---
    analysis_story = ""
    estimated_fix = "Belirsiz"
    
    if segment_color == "GREEN":
        analysis_story = f"{region} bÃ¶lgesindeki altyapÄ± analiz edildi ve tÃ¼m parametreler normal aralÄ±kta tespit edildi. HattÄ±nÄ±zda herhangi bir fiziksel veya yazÄ±lÄ±msal sorun bulunmamaktadÄ±r. LSTM trend analizi ve Random Forest sÄ±nÄ±flandÄ±rma modelleri de baÄŸlantÄ±nÄ±zÄ±n stabil olduÄŸunu doÄŸruluyor. Sistem sÃ¼rekli izleme altÄ±ndadÄ±r."
        estimated_fix = "Gerekli deÄŸil"
    else:
        # Story logic
        if region_fault_count > 5:
            analysis_story = f"{region} bÃ¶lgesinde kritik seviyede altyapÄ± sorunu tespit edildi. Sorun sadece sizin hattÄ±nÄ±zda deÄŸil, bÃ¶lge genelindeki {region_fault_count} aboneyi etkiliyor. Analiz sonuÃ§larÄ± ana daÄŸÄ±tÄ±m noktasÄ±nda (MDF/ODF) fiziksel veya konfigÃ¼rasyon problemi olduÄŸunu gÃ¶steriyor. Saha ekiplerimiz acil mÃ¼dahale iÃ§in gÃ¶revlendirilmiÅŸtir. Fiber altyapÄ± testi ve daÄŸÄ±tÄ±m noktasÄ± kontrolÃ¼ yapÄ±lacaktÄ±r. Bu tÃ¼r bÃ¶lgesel arÄ±zalar genellikle 2-4 saat iÃ§inde Ã§Ã¶zÃ¼lmektedir."
            estimated_fix = "2-4 Saat"
        else:
            # Determine specific issue type
            issue_type = "yÃ¼ksek gecikme (latency)" if live_data['latency'] > 50 else "paket kaybÄ±"
            issue_value = f"{live_data['latency']:.0f} ms" if live_data['latency'] > 50 else f"%{live_data.get('packet_loss', 0):.1f}"
            
            analysis_story = f"{region} bÃ¶lgesinde yaygÄ±n bir sorun tespit edilmedi. Modem ({modem}, IP: {ip}) ile santral arasÄ±ndaki sinyal kalitesinde degradasyon gÃ¶rÃ¼lmektedir. Hat deÄŸerlerinizde anlÄ±k {issue_type} ({issue_value}) Ã¶lÃ§Ã¼lmÃ¼ÅŸtÃ¼r. BÃ¶lgede baÅŸka abone etkilenmediÄŸinden, problem mÃ¼ÅŸteri lokasyonu ile sÄ±nÄ±rlÄ±dÄ±r. Saha teknisyeni gÃ¶ndererek iÃ§ tesisat kontrolÃ¼ ve modem sinyal seviyesi Ã¶lÃ§Ã¼mÃ¼ yaptÄ±rmanÄ±zÄ± Ã¶neriyoruz. Gerekirse ekipman deÄŸiÅŸimi planlanabilir. Bu tÃ¼r tekil hat arÄ±zalarÄ±nÄ±n Ã§Ã¶zÃ¼mÃ¼ ortalama 45 dakika sÃ¼rmektedir."
            estimated_fix = "45 Dakika"


    sms_info = {"sent": False, "message": None}

    return {
        "subscriber_id": subscriber_id,
        "customer_info": {
            "name": name, "plan": plan, "region": region, "phone": phone,
            "modem": modem, "ip": ip, "uptime": uptime
        },
        "live_metrics": live_data,
        "ai_analysis": {
            "segment": segment_color,
            "risk_score": final_risk,
            "reason": ensemble_reason,
            "story": analysis_story,
            "estimated_fix": estimated_fix
        },
        "history": [
            {"date": h[0].strftime("%d.%m.%Y %H:%M"), "event": h[1], "status": h[2], "tech": h[3]} 
            for h in history
        ],
        "sms_notification": sms_info
    }

# --- 2. ENDPOINT: TOPLU TARAMA (Dashboard Ä°Ã§in) ---
@app.get("/api/scan_network")
def scan_network_batch():
    """
    TÃ¼m aboneleri (veya ilk 500'Ã¼) tarar, anlÄ±k durumlarÄ±nÄ± simÃ¼le eder 
    ve gruplandÄ±rÄ±r.
    """
    conn = get_db_connection()
    if not conn: raise HTTPException(status_code=500, detail="Database fail")
    
    cursor = conn.cursor()
    # Performans iÃ§in sadece gerekli kolonlarÄ± Ã§ekiyoruz
    cursor.execute("SELECT subscriber_id, full_name, subscription_plan, region_id FROM customers LIMIT 500")
    customers = cursor.fetchall()
    
    results = {
        "total": len(customers),
        "counts": {"GREEN": 0, "YELLOW": 0, "RED": 0},
        "lists": {"GREEN": [], "YELLOW": [], "RED": []}
    }
    
    # Toplu SimÃ¼lasyon DÃ¶ngÃ¼sÃ¼
    for cust in customers:
        sub_id, name, plan, region = cust
        
        # GerÃ§ekÃ§i DaÄŸÄ±lÄ±m Ä°Ã§in Zar AtÄ±yoruz:
        # %90 YeÅŸil, %7 SarÄ±, %3 KÄ±rmÄ±zÄ±
        rand_val = random.randint(0, 100)
        
        # HÄ±zlÄ± simÃ¼lasyon (Tekil fonksiyondan daha basit veriler)
        metrics = {
            "latency": random.uniform(10, 40),
            "packet_loss": 0,
            "download_speed": 100,
            "jitter": random.uniform(1, 5)
        }
        
        ai_pred = 0
        
        # KÄ±rmÄ±zÄ± Durumu SimÃ¼le Et (%3)
        if rand_val > 97:
            metrics["packet_loss"] = random.uniform(10, 30)
            metrics["download_speed"] = 2.0
            ai_pred = 2
        # SarÄ± Durumu SimÃ¼le Et (%7)
        elif rand_val > 90:
            metrics["latency"] = random.uniform(90, 180) # Ping yÃ¼kselmiÅŸ
            metrics["jitter"] = random.uniform(20, 50)
            ai_pred = 0 # AI henÃ¼z hata demiyor ama biz RISK gÃ¶rÃ¼yoruz
            
        # Segmentasyon Fonksiyonunu Ã‡aÄŸÄ±r
        color = classify_subscriber_status(metrics, ai_pred)
        
        # [NEW] DURUMU VERÄ°TABANINA KAYDET (Senkronizasyon Ä°Ã§in)
        try:
            with conn.cursor() as cur:
                cur.execute("""
                    INSERT INTO subscriber_status (subscriber_id, current_status, last_checked)
                    VALUES (%s, %s, NOW())
                    ON CONFLICT (subscriber_id) 
                    DO UPDATE SET current_status = EXCLUDED.current_status, last_checked = NOW()
                """, (sub_id, color))
                conn.commit()
        except Exception as e:
            print(f"Status update error: {e}")
            conn.rollback()

        # Ä°statistiklere Ekle
        results["counts"][color] += 1
        
        # Listeye Ekle (ARTIK TÃœM ABONELER EKLENÄ°YOR)
        issue_text = "Stabil"
        if color == "YELLOW": issue_text = "YÃ¼ksek Ping"
        elif color == "RED": issue_text = "BaÄŸlantÄ± Kopuk"
        
        results["lists"][color].append({
            "id": sub_id,
            "name": name,
            "region": region, 
            "plan": plan,
            "issue": issue_text,
            "metrics": metrics
        })
    
    conn.close()
    return results


# --- 3. ENDPOINT: LSTM TREND ANALÄ°ZÄ° (YENÄ°!) ---
@app.get("/api/trend/{subscriber_id}")
def get_trend_analysis(subscriber_id: int):
    """
    LSTM-based trend analysis for proactive monitoring
    Returns detailed risk forecast and trend direction
    """
    if not lstm_service.is_available:
        raise HTTPException(
            status_code=503, 
            detail="LSTM service unavailable. Model not loaded."
        )
    
    # Get trend analysis
    trend = lstm_service.analyze_trend(subscriber_id)
    
    if not trend:
        # Not enough data yet
        cache_size = len(lstm_service.measurement_cache.get(subscriber_id, []))
        raise HTTPException(
            status_code=400,
            detail=f"Not enough data for trend analysis. Have {cache_size}/12 measurements. Need 1 hour of data."
        )
    
    # Get customer info
    conn = get_db_connection()
    customer_name = "Unknown"
    if conn:
        cursor = conn.cursor()
        cursor.execute("SELECT full_name FROM customers WHERE subscriber_id = %s", (subscriber_id,))
        result = cursor.fetchone()
        if result:
            customer_name = result[0]
        conn.close()
    
    return {
        "subscriber_id": subscriber_id,
        "customer_name": customer_name,
        "analysis": {
            "current_risk": round(trend.current_risk, 3),
            "trend_direction": trend.trend_direction,
            "forecast_30min": round(trend.forecast_30min, 3),
            "risk_chart": [round(r, 3) for r in trend.risk_chart],
            "recommendation": trend.recommendation,
            "severity": "HIGH" if trend.forecast_30min > 0.7 else ("MEDIUM" if trend.forecast_30min > 0.4 else "LOW")
        },
        "metadata": {
            "measurements_count": len(trend.risk_chart),
            "window_size": lstm_service.window_size,
            "model_status": "active",
            "model_name": "LSTM"
        }
    }
# === STARTUP & SHUTDOWN EVENTS ===

@app.on_event("startup")
async def startup_event():
    """
    Backend baÅŸlangÄ±cÄ±nda:
    1. TÃ¼m 500 abone iÃ§in LSTM cache oluÅŸtur (12 Ã¶lÃ§Ã¼m)
    2. Otomatik periodic monitoring baÅŸlat (her 5 dakika)
    """
    global background_monitor
    
    logger.info("ğŸš€ NetPulse Backend baÅŸlatÄ±lÄ±yor...")
    
    if lstm_service and lstm_service.is_available:
        background_monitor = BackgroundMonitor(
            get_db_func=get_db_connection,
            lstm_service=lstm_service,
            simulate_func=simulate_metrics_single
        )
        
        await background_monitor.start()
        logger.info("âœ… Background monitoring aktif! (500 abone)")
    else:
        logger.warning("âš ï¸ LSTM unavailable, background monitoring disabled")


@app.on_event("shutdown")
async def shutdown_event():
    """Backend kapatÄ±lÄ±rken monitoring durdur"""
    if background_monitor:
        background_monitor.stop()
    logger.info("ğŸ‘‹ NetPulse Backend kapatÄ±ldÄ±")
