from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional
import psycopg2
import pandas as pd
import joblib
import os
import random
import time
import logging
from datetime import datetime
import llm_service, sms_sender
from lstm_service import (
    LSTMPredictionService,
    HybridEnsembleModel,
    PredictionResult
)
from status_tracker import StatusTracker
from background_monitor import BackgroundMonitor

logger = logging.getLogger(__name__)

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
MODEL_PATH = os.path.join(BASE_DIR, 'saved_models', 'netpulse_classifier.pkl')

# LSTM Model Paths
LSTM_MODEL_PATH = os.path.join(BASE_DIR, 'saved_models', 'netpulse_lstm.h5')
LSTM_SCALER_PATH = os.path.join(BASE_DIR, 'saved_models', 'lstm_scaler.pkl')
LSTM_ENCODER_PATH = os.path.join(BASE_DIR, 'saved_models', 'lstm_encoder.pkl')

DB_CONFIG = {
    "dbname": "netpulse_db",
    "user": "postgres",
    "password": "admin",
    "host": "localhost",
    "port": "5432"
}

# Load Random Forest Model
model = None
try:
    model = joblib.load(MODEL_PATH)
    logger.info("‚úÖ Random Forest model loaded")
except Exception as e:
    logger.warning(f"‚ö†Ô∏è Random Forest load failed: {e}")

# Initialize LSTM Service
lstm_service = LSTMPredictionService(
    LSTM_MODEL_PATH, LSTM_SCALER_PATH, LSTM_ENCODER_PATH
)

# Initialize Hybrid Ensemble Model
hybrid_model = HybridEnsembleModel(rf_weight=0.6, lstm_weight=0.4)

# Background Monitor (initialized at startup)
background_monitor = None

def get_db_connection():
    try:
        return psycopg2.connect(**DB_CONFIG)
    except:
        return None

# --- YARDIMCI FONKSƒ∞YONLAR ---

def generate_fault_scenario(scenario_type):
    """Arƒ±za t√ºr√ºne g√∂re mantƒ±klƒ± bir SEBEP, AKSƒ∞YON ve S√úRE √ºretir."""
    if scenario_type == "ping":
        return {"cause": "B√∂lgesel veri trafiƒüi yoƒüunluƒüu", "action": "Y√ºk dengeleme aktif edildi", "eta": "30 dk"}
    elif scenario_type == "speed":
        return {"cause": "Ana fiber omurgada sinyal zayƒ±flamasƒ±", "action": "Santral optimizasyonu ba≈ülatƒ±ldƒ±", "eta": "1 saat"}
    elif scenario_type == "loss":
        return {"cause": "Saha dolabƒ±nda donanƒ±m arƒ±zasƒ±", "action": "Saha ekibi y√∂nlendirildi", "eta": "3 saat"}
    else:
        return {"cause": "Planlƒ± bakƒ±m √ßalƒ±≈ümasƒ±", "action": "Sistem g√ºncelleniyor", "eta": "15 dk"}

def simulate_metrics_single(plan, force_trouble=False):
    """Tekil kullanƒ±cƒ± i√ßin detaylƒ± sim√ºlasyon (Eski fonksiyonumuz)"""
    is_problem = random.random() < 0.2 or force_trouble
    
    metrics = {
        "latency": random.uniform(10, 50),
        "packet_loss": random.uniform(0, 0.05),
        "jitter": random.uniform(1, 10),
        "download_speed": 100.0,
        "upload_speed": 20.0,
        "signal_strength": random.uniform(-60, -30),
        "connected_devices": random.randint(1, 10)
    }
    
    fault_details = None

    if "1000" in plan: metrics["download_speed"] = random.uniform(800, 1000)
    elif "100" in plan: metrics["download_speed"] = random.uniform(80, 100)
    else: metrics["download_speed"] = random.uniform(20, 50)

    if is_problem:
        scenario_type = random.choice(["ping", "speed", "loss"])
        if force_trouble: scenario_type = "loss"
        
        if scenario_type == "ping":
            metrics["latency"] = random.uniform(150, 400)
            metrics["jitter"] = random.uniform(50, 150)
        elif scenario_type == "speed":
            metrics["download_speed"] = random.uniform(1, 10)
        elif scenario_type == "loss":
            metrics["packet_loss"] = random.uniform(10, 40)
            metrics["signal_strength"] = random.uniform(-90, -80)
            
        fault_details = generate_fault_scenario(scenario_type)

    return metrics, fault_details, is_problem

# --- YENƒ∞ EKLENEN KISIM: TRAFFIC LIGHT SEGMENTASYONU ---

def classify_subscriber_status(metrics, ai_prediction):
    """
    Traffic Light Algoritmasƒ±:
    Ham verileri ve AI tahminini birle≈ütirip RENK kararƒ± verir.
    """
    # 1. Kƒ±rmƒ±zƒ± Kuralƒ± (Kritik)
    if ai_prediction in [2, 3] or metrics['packet_loss'] > 5 or metrics['download_speed'] < 5:
        return "RED"
    
    # 2. Sarƒ± Kuralƒ± (Riskli / Warning)
    # AI 'Normal' dese bile Ping y√ºksekse veya Hƒ±z dalgalƒ±ysa SARI yak.
    # Bu, "Kestirimci Bakƒ±m" (Predictive) √∂zelliƒüidir.
    if metrics['latency'] > 80 or metrics['jitter'] > 30 or ai_prediction == 1:
        return "YELLOW"
    
    # 3. Ye≈üil Kuralƒ± (Normal)
    return "GREEN"

@app.get("/")
def home():
    return {
        "status": "active", 
        "mode": "Enterprise NOC",
        "lstm_available": lstm_service.is_available
    }

from pydantic import BaseModel
from typing import List, Optional

# --- YARDIMCI ENDPOINTLER ---

@app.get("/api/technicians")
def get_technicians():
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("SELECT id, name, expertise, status FROM technicians")
    techs = cursor.fetchall()
    conn.close()
    return [{"id": t[0], "name": t[1], "expertise": t[2], "status": t[3]} for t in techs]

@app.post("/api/actions/{action_type}")
def perform_action(action_type: str, subscriber_id: int = 0):
    # Simulate action
    time.sleep(1) # Fake delay
    return {"status": "Success", "message": f"{action_type} i≈ülemi ba≈üarƒ±yla tamamlandƒ±."}

# --- 1. ENDPOINT: TEKƒ∞L ANALƒ∞Z (Geli≈ümi≈ü) ---
@app.get("/api/simulate/{subscriber_id}")
def simulate_network(subscriber_id: int, force_trouble: bool = False):
    conn = get_db_connection()
    if not conn: raise HTTPException(status_code=500, detail="Database fail")
    
    cursor = conn.cursor()
    # Fetch extended info
    cursor.execute("""
        SELECT full_name, subscription_plan, region_id, gender, phone_number, modem_model, ip_address, uptime 
        FROM customers WHERE subscriber_id = %s
    """, (subscriber_id,))
    customer = cursor.fetchone()
    
    if not customer: 
        conn.close()
        raise HTTPException(status_code=404, detail="User not found")

    name, plan, region, gender, phone, modem, ip, uptime = customer
    
    # Generate unique location based on subscriber_id  
    # ƒ∞stanbul b√∂lgeleri i√ßin yakla≈üƒ±k koordinatlar
    region_coords = {
        "Kadƒ±k√∂y": (40.99, 29.03),
        "Be≈üikta≈ü": (41.04, 29.00),
        "√úsk√ºdar": (41.02, 29.01),
        "≈ûi≈üli": (41.06, 28.99),
        "Bakƒ±rk√∂y": (40.98, 28.87)
    }
    
    base_region = region.split('/')[0]  # "Kadƒ±k√∂y/Moda" -> "Kadƒ±k√∂y"
    base_lat, base_lon = region_coords.get(base_region, (41.01, 28.98))
    
    # Her abone i√ßin benzersiz offset (subscriber_id'ye g√∂re deterministic)
    import hashlib
    hash_val = int(hashlib.md5(str(subscriber_id).encode()).hexdigest(), 16)
    lat_offset = (hash_val % 100) / 10000.0  # 0.0000-0.0099 arasƒ±
    lon_offset = ((hash_val // 100) % 100) / 10000.0
    
    subscriber_lat = base_lat + lat_offset - 0.005  # Merkezden sapma
    subscriber_lon = base_lon + lon_offset - 0.005
    
    # Rastgele sokak adƒ± (subscriber_id'ye g√∂re deterministic)
    street_names = ["Baƒüdat Caddesi", "Nispetiye Caddesi", "Acƒ±badem Caddesi", 
                    "Te≈üvikiye Caddesi", "Atat√ºrk Caddesi", "Cumhuriyet Caddesi",
                    "ƒ∞stiklal Caddesi", "Bahariye Caddesi", "Moda Caddesi"]
    street_index = subscriber_id % len(street_names)
    building_no = (subscriber_id % 200) + 1
    location_address = f"{street_names[street_index]} No:{building_no}, {region}"
    
    # Fetch Recent Tickets (YENƒ∞ SCHEMA)
    cursor.execute("""
        SELECT t.created_at, t.fault_type, t.status, t.assigned_to
        FROM tickets t 
        WHERE t.subscriber_id = %s 
        ORDER BY t.created_at DESC LIMIT 5
    """, (subscriber_id,))
    history = cursor.fetchall()
    
    # Analyze Region Status (For Storytelling)
    # Count faulty users in same region
    cursor.execute("""
        SELECT COUNT(*) FROM customers c
        JOIN subscriber_status ss ON c.subscriber_id = ss.subscriber_id
        WHERE c.region_id = %s AND ss.current_status IN ('RED', 'YELLOW')
    """, (region,))
    region_fault_count = cursor.fetchone()[0]
    
    # Simulate Live Metrics
    # [NEW] SYNC WITH DB STATUS
    # List sayfasƒ±nda ne g√∂r√ºn√ºyorsa detayda da o g√∂r√ºnmeli.
    cursor.execute("SELECT current_status FROM subscriber_status WHERE subscriber_id = %s", (subscriber_id,))
    row = cursor.fetchone()
    db_status = row[0] if row else None
    
    conn.close()

    # Eƒüer DB'de bir sorun kaydƒ± varsa, sim√ºlasyonu ona g√∂re zorla
    force_metrics_state = None
    if db_status == "RED" or db_status == "YELLOW":
        force_metrics_state = db_status

    live_data, fault_details, is_faulty = simulate_metrics_single(plan, force_trouble=(force_trouble or force_metrics_state is not None))
    
    # Override metrics if specific state needed to match DB
    if force_metrics_state == "RED":
        live_data["packet_loss"] = random.uniform(15, 40)
        live_data["download_speed"] = random.uniform(0.1, 3.0)
    elif force_metrics_state == "YELLOW":
        live_data["latency"] = random.uniform(90, 250)
        live_data["jitter"] = random.uniform(30, 80)
    
    # ... (Rest of AI logic same as before, condensed for brevity) ...
    # Re-implementing simplified AI logic just for this response to ensure flow consistency
    # In real file, we would keep the existing LSTM/RF logic. 
    # Since I'm replacing the whole function block, I need to include it or reference it.
    
    # Let's re-use the existing global objects: lstm_service, model, hybrid_model
    
    # 1. LSTM
    lstm_result = None
    if lstm_service and lstm_service.is_available:
        lstm_service.add_measurement(subscriber_id, live_data)
        lstm_result = lstm_service.predict(subscriber_id)
        
    # 2. RF
    prediction_code = 0
    rf_confidence = 0.5
    try:
        prediction_code = int(model.predict(pd.DataFrame([live_data]))[0]) if model else 0
    except: pass
    
    rf_result = PredictionResult("RandomForest", prediction_code, rf_confidence, [], datetime.now())
    
    # 3. Hybrid
    final_risk, segment_color, ensemble_reason = hybrid_model.combine_predictions(rf_result, lstm_result) if hybrid_model else (0, "GREEN", "System Log")
    
    # [KRITIK] Status Persistence - Prevent rapid status flipping
    # Use StatusTracker to enforce minimum durations (RED=10min, YELLOW=5min)
    try:
        tracker = StatusTracker(conn)
        
        # Check if we're allowed to change to the AI-predicted status
        permission = tracker.should_allow_status_change(subscriber_id, segment_color)
        
        if not permission["allowed"]:
            # Status change blocked - keep old status
            logger.info(f"‚è∏Ô∏è Status change blocked for {subscriber_id}: {permission['reason']}")
            # DB status varsa onu kullan, yoksa GREEN
            segment_color = db_status if db_status else "GREEN"
            ensemble_reason = f"Status locked: {permission['reason']}"
        elif db_status and db_status != segment_color:
            # Status change allowed and different from DB - update via tracker
            logger.info(f"‚úÖ Status change allowed for {subscriber_id}: {db_status} ‚Üí {segment_color}")
            tracker.update_status(subscriber_id, segment_color, fault_type="network_degradation")
        elif not db_status:
            # First time - initialize status
            tracker.update_status(subscriber_id, segment_color)
    except Exception as e:
        logger.error(f"‚ùå StatusTracker error for {subscriber_id}: {e}")
        # Fallback to old behavior
        if db_status and db_status in ["RED", "YELLOW", "GREEN"]:
            segment_color = db_status
            ensemble_reason = f"DB synchronized status ({db_status})"

    
    # --- DETAILED NARRATIVE ANALYSIS ---
    analysis_story = ""
    estimated_fix = "Belirsiz"
    
    if segment_color == "GREEN":
        analysis_story = f"{region} b√∂lgesindeki altyapƒ± analiz edildi ve t√ºm parametreler normal aralƒ±kta tespit edildi. Hattƒ±nƒ±zda herhangi bir fiziksel veya yazƒ±lƒ±msal sorun bulunmamaktadƒ±r. LSTM trend analizi ve Random Forest sƒ±nƒ±flandƒ±rma modelleri de baƒülantƒ±nƒ±zƒ±n stabil olduƒüunu doƒüruluyor. Sistem s√ºrekli izleme altƒ±ndadƒ±r."
        estimated_fix = "Gerekli deƒüil"
    else:
        # Story logic
        if region_fault_count > 5:
            analysis_story = f"{region} b√∂lgesinde kritik seviyede altyapƒ± sorunu tespit edildi. Sorun sadece sizin hattƒ±nƒ±zda deƒüil, b√∂lge genelindeki {region_fault_count} aboneyi etkiliyor. Analiz sonu√ßlarƒ± ana daƒüƒ±tƒ±m noktasƒ±nda (MDF/ODF) fiziksel veya konfig√ºrasyon problemi olduƒüunu g√∂steriyor. Saha ekiplerimiz acil m√ºdahale i√ßin g√∂revlendirilmi≈ütir. Fiber altyapƒ± testi ve daƒüƒ±tƒ±m noktasƒ± kontrol√º yapƒ±lacaktƒ±r. Bu t√ºr b√∂lgesel arƒ±zalar genellikle 2-4 saat i√ßinde √ß√∂z√ºlmektedir."
            estimated_fix = "2-4 Saat"
        else:
            # Determine specific issue type
            issue_type = "y√ºksek gecikme (latency)" if live_data['latency'] > 50 else "paket kaybƒ±"
            issue_value = f"{live_data['latency']:.0f} ms" if live_data['latency'] > 50 else f"%{live_data.get('packet_loss', 0):.1f}"
            
            analysis_story = f"{region} b√∂lgesinde yaygƒ±n bir sorun tespit edilmedi. Modem ({modem}, IP: {ip}) ile santral arasƒ±ndaki sinyal kalitesinde degradasyon g√∂r√ºlmektedir. Hat deƒüerlerinizde anlƒ±k {issue_type} ({issue_value}) √∂l√ß√ºlm√º≈üt√ºr. B√∂lgede ba≈üka abone etkilenmediƒüinden, problem m√º≈üteri lokasyonu ile sƒ±nƒ±rlƒ±dƒ±r. Saha teknisyeni g√∂ndererek i√ß tesisat kontrol√º ve modem sinyal seviyesi √∂l√ß√ºm√º yaptƒ±rmanƒ±zƒ± √∂neriyoruz. Gerekirse ekipman deƒüi≈üimi planlanabilir. Bu t√ºr tekil hat arƒ±zalarƒ±nƒ±n √ß√∂z√ºm√º ortalama 45 dakika s√ºrmektedir."
            estimated_fix = "45 Dakika"


    sms_info = {"sent": False, "message": None}

    return {
        "subscriber_id": subscriber_id,
        "customer_info": {
            "name": name, "plan": plan, "region": region, "phone": phone,
            "modem": modem, "ip": ip, "uptime": uptime, "gender": gender,
            "location": {
                "latitude": subscriber_lat,
                "longitude": subscriber_lon,
                "address": location_address
            }
        },
        "live_metrics": live_data,
        "ai_analysis": {
            "segment": segment_color,
            "risk_score": final_risk,
            "reason": ensemble_reason,
            "story": analysis_story,
            "estimated_fix": estimated_fix
        },
        "history": [
            {"date": h[0].strftime("%d.%m.%Y %H:%M"), "event": h[1], "status": h[2], "tech": h[3]} 
            for h in history
        ],
        "sms_notification": sms_info
    }

# --- 2. ENDPOINT: TOPLU TARAMA (Dashboard ƒ∞√ßin) ---
@app.get("/api/scan_network")
def scan_network_batch():
    """
    T√ºm aboneleri (veya ilk 500'√º) tarar, anlƒ±k durumlarƒ±nƒ± sim√ºle eder 
    ve gruplandƒ±rƒ±r.
    """
    conn = get_db_connection()
    if not conn: raise HTTPException(status_code=500, detail="Database fail")
    
    cursor = conn.cursor()
    # Performans i√ßin sadece gerekli kolonlarƒ± √ßekiyoruz
    cursor.execute("SELECT subscriber_id, full_name, subscription_plan, region_id FROM customers LIMIT 500")
    customers = cursor.fetchall()
    
    results = {
        "total": len(customers),
        "counts": {"GREEN": 0, "YELLOW": 0, "RED": 0},
        "lists": {"GREEN": [], "YELLOW": [], "RED": []}
    }
    
    # Toplu Sim√ºlasyon D√∂ng√ºs√º
    for cust in customers:
        sub_id, name, plan, region = cust
        
        # Ger√ßek√ßi Daƒüƒ±lƒ±m ƒ∞√ßin Zar Atƒ±yoruz:
        # Persistence (10dk) olduƒüu i√ßin √ßok d√º≈ü√ºk olasƒ±lƒ±klar kullanƒ±yoruz
        # Hedef: 500 ki≈üide anlƒ±k ~5-10 RED, ~15-20 YELLOW
        rand_val = random.uniform(0, 100)
        
        # Hƒ±zlƒ± sim√ºlasyon (Tekil fonksiyondan daha basit veriler)
        metrics = {
            "latency": random.uniform(10, 40),
            "packet_loss": 0,
            "download_speed": 100,
            "jitter": random.uniform(1, 5)
        }
        
        ai_pred = 0
        
        
        
        # Kƒ±rmƒ±zƒ± Durumu Sim√ºle Et (%0.05 Olasƒ±lƒ±k -> Her 2000 taramada 1)
        # Hedef: Peak Hour sim√ºlasyonunu (25 RED) canlƒ± tutmak
        if rand_val > 99.95:
            metrics["packet_loss"] = random.uniform(10, 30)
            metrics["download_speed"] = 2.0
            ai_pred = 2
        # Sarƒ± Durumu Sim√ºle Et (%0.3 Olasƒ±lƒ±k -> Her 333 taramada 1)
        # Hedef: Proaktif analiz (50 YELLOW) havuzunu beslemek
        elif rand_val > 99.7:
            metrics["latency"] = random.uniform(90, 180) # Ping y√ºkselmi≈ü
            metrics["jitter"] = random.uniform(20, 50)
            ai_pred = 0 # AI hen√ºz hata demiyor ama biz RISK g√∂r√ºyoruz
            
        # Segmentasyon Fonksiyonunu √áaƒüƒ±r
        proposed_color = classify_subscriber_status(metrics, ai_pred)
        
        # [PERSISTENCE] Status Tracker Entegrasyonu
        # Random √ºretim GREEN dese bile, eƒüer DB'de RED varsa ve s√ºre dolmadƒ±ysa RED kalmalƒ±
        
        final_color = proposed_color
        try:
            tracker = StatusTracker(conn)
            permission = tracker.should_allow_status_change(sub_id, proposed_color)
            
            if permission["allowed"]:
                # Deƒüi≈üikliƒüe izin var, yeni durumu kaydet
                if proposed_color != "GREEN": # Sadece sorunlarƒ± logla, performansƒ± koru
                    logger.info(f"‚ö° Batch Scan: Status change allowed for {sub_id}: ‚Üí {proposed_color}")
                
                tracker.update_status(sub_id, proposed_color)
                final_color = proposed_color
            else:
                # ƒ∞zin yok, mevcut durumu koru (DB'den ne geldiyse o)
                # Ancak DB stat√ºs√ºn√º bilmiyoruz, sorgulamamƒ±z lazƒ±m
                current_status_info = tracker.get_current_status(sub_id)
                final_color = current_status_info["current"]
                # logger.info(f"üîí Batch Scan: Status change blocked for {sub_id}: {permission['reason']}")

        except Exception as e:
            logger.error(f"Batch scan persistence error: {e}")
            # Hata durumunda proposed kullan
            final_color = proposed_color
            
        color = final_color

        # ƒ∞statistiklere Ekle
        results["counts"][color] += 1
        
        # Listeye Ekle (ARTIK T√úM ABONELER EKLENƒ∞YOR)
        issue_text = "Stabil"
        if color == "YELLOW": issue_text = "Y√ºksek Ping"
        elif color == "RED": issue_text = "Baƒülantƒ± Kopuk"
        
        results["lists"][color].append({
            "id": sub_id,
            "name": name,
            "region": region, 
            "plan": plan,
            "issue": issue_text,
            "metrics": metrics
        })
    
    conn.close()
    return results


# --- 3. ENDPOINT: LSTM TREND ANALƒ∞Zƒ∞ (YENƒ∞!) ---
@app.get("/api/trend/{subscriber_id}")
def get_trend_analysis(subscriber_id: int):
    """
    LSTM-based trend analysis for proactive monitoring
    Returns detailed risk forecast and trend direction
    """
    if not lstm_service.is_available:
        raise HTTPException(
            status_code=503, 
            detail="LSTM service unavailable. Model not loaded."
        )
    
    # Get trend analysis
    trend = lstm_service.analyze_trend(subscriber_id)
    
    if not trend:
        # Not enough data yet
        cache_size = len(lstm_service.measurement_cache.get(subscriber_id, []))
        raise HTTPException(
            status_code=400,
            detail=f"Not enough data for trend analysis. Have {cache_size}/12 measurements. Need 1 hour of data."
        )
    
    # Get customer info
    conn = get_db_connection()
    customer_name = "Unknown"
    if conn:
        cursor = conn.cursor()
        cursor.execute("SELECT full_name FROM customers WHERE subscriber_id = %s", (subscriber_id,))
        result = cursor.fetchone()
        if result:
            customer_name = result[0]
        conn.close()
    
    return {
        "subscriber_id": subscriber_id,
        "customer_name": customer_name,
        "analysis": {
            "current_risk": round(trend.current_risk, 3),
            "trend_direction": trend.trend_direction,
            "forecast_30min": round(trend.forecast_30min, 3),
            "risk_chart": [round(r, 3) for r in trend.risk_chart],
            "recommendation": trend.recommendation,
            "severity": "HIGH" if trend.forecast_30min > 0.7 else ("MEDIUM" if trend.forecast_30min > 0.4 else "LOW")
        },
        "metadata": {
            "measurements_count": len(trend.risk_chart),
            "window_size": lstm_service.window_size,
            "model_status": "active",
            "model_name": "LSTM"
        }
    }
# === STARTUP & SHUTDOWN EVENTS ===

@app.on_event("startup")
async def startup_event():
    """
    Backend ba≈ülangƒ±cƒ±nda:
    1. T√ºm 500 abone i√ßin LSTM cache olu≈ütur (12 √∂l√ß√ºm)
    2. Otomatik periodic monitoring ba≈ülat (her 5 dakika)
    """
    global background_monitor
    
    logger.info("üöÄ NetPulse Backend ba≈ülatƒ±lƒ±yor...")
    
    if lstm_service and lstm_service.is_available:
        background_monitor = BackgroundMonitor(
            get_db_func=get_db_connection,
            lstm_service=lstm_service,
            simulate_func=simulate_metrics_single
        )
        
        await background_monitor.start()
        logger.info("‚úÖ Background monitoring aktif! (500 abone)")
    else:
        logger.warning("‚ö†Ô∏è LSTM unavailable, background monitoring disabled")


@app.on_event("shutdown")
async def shutdown_event():
    """Backend kapatƒ±lƒ±rken monitoring durdur"""
    if background_monitor:
        background_monitor.stop()
    logger.info("üëã NetPulse Backend kapatƒ±ldƒ±")

# --- 3. ENDPOINT: ENHANCED TICKET NOTE GENERATION (LLM Style) ---
class SMSRequest(BaseModel):
    phone_number: str
    message: str

@app.post("/api/send-sms")
def send_sms_notification(request: SMSRequest):
    """
    Send SMS notification via Vonage
    """
    try:
        success, response_msg = sms_sender.send_sms(request.phone_number, request.message)
        if success:
            return {"status": "success", "message": response_msg}
        else:
            raise HTTPException(status_code=500, detail=response_msg)
    except Exception as e:
        logger.error(f"SMS Endpoint Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

class TicketRequest(BaseModel):
    subscriber_id: int
    current_status: str
    ai_analysis: str
    live_metrics: Optional[dict] = None

@app.post("/api/generate_ticket_note")
def generate_ticket_note(request: TicketRequest):
    """
    Profesyonel teknisyen notu olu≈üturur - Structured JSON formatƒ±nda d√∂ner
    """
    try:
        conn = get_db_connection()
        if not conn:
            raise HTTPException(status_code=500, detail="Database fail")
        
        cursor = conn.cursor()
        
        # 1. Abone bilgilerini al
        cursor.execute("""
            SELECT region_id, modem_model 
            FROM customers WHERE subscriber_id = %s
        """, (request.subscriber_id,))
        cust_data = cursor.fetchone()
        
        if not cust_data:
             return {
                 "scope": "INDIVIDUAL", 
                 "neighbor_count": 0,
                 "header": {},
                 "metrics": {},
                 "diagnosis": {},
                 "actions": []
             }
             
        region_id, modem_model = cust_data
        
        # 2. B√∂lgesel Analiz
        cursor.execute("""
            SELECT COUNT(*) 
            FROM customers c
            JOIN subscriber_status s ON c.subscriber_id = s.subscriber_id
            WHERE c.region_id = %s 
              AND s.current_status IN ('RED', 'YELLOW')
              AND c.subscriber_id != %s
        """, (region_id, request.subscriber_id))
        
        neighbor_faults = cursor.fetchone()[0]
        conn.close()
        
        # 3. Kapsam Belirleme
        scope = "REGIONAL" if neighbor_faults > 3 else "INDIVIDUAL"
        
        # 4. √ñncelik ve Durum
        priority_map = {
            "RED": ("Y√úKSEK", "üî¥"),
            "YELLOW": ("ORTA", "üü°"),
            "GREEN": ("D√ú≈û√úK", "üü¢")
        }
        priority, status_icon = priority_map.get(request.current_status, ("D√ú≈û√úK", "‚ö™"))
        
        status_tr = {
            "RED": "KIRMIZI (Kritik Arƒ±za)",
            "YELLOW": "SARI (Performans D√º≈ü√ºkl√ºƒü√º)",
            "GREEN": "YE≈ûƒ∞L (Normal)"
        }
        
        # 5. Metrikler
        metrics = request.live_metrics or {}
        latency = metrics.get('latency', 0)
        packet_loss = metrics.get('packet_loss', 0)
        download_speed = metrics.get('download_speed', 0)
        jitter = metrics.get('jitter', 0)
        
        metrics_data = {
            "latency": {"value": latency, "unit": "ms", "threshold": 50, "ok": latency < 50},
            "packet_loss": {"value": packet_loss, "unit": "%", "threshold": 1, "ok": packet_loss < 1},
            "download_speed": {"value": download_speed, "unit": "Mbps", "threshold": 50, "ok": download_speed > 50},
            "jitter": {"value": jitter, "unit": "ms", "threshold": 10, "ok": jitter < 10}
        }
        
        # 6. Te≈ühis ve Aksiyonlar
        diagnosis = ""
        actions = []
        estimated_time = ""
        
        if request.current_status == "RED":
            if scope == "REGIONAL":
                diagnosis = f"B√∂lgesel Altyapƒ± Arƒ±zasƒ± - {region_id} b√∂lgesinde yaygƒ±n sorun tespit edildi."
                actions = [
                    f"[ACƒ∞L] {region_id} b√∂lge switch'ini ve OLT'yi kontrol edin",
                    "Fiber hat g√º√ß seviyelerini test edin (PON power levels)",
                    "B√∂lgesel sorun √ß√∂z√ºlmeden m√º≈üteri evine ekip G√ñNDERMEYƒ∞N",
                    f"Diƒüer etkilenen {neighbor_faults} aboneyi toplu bilgilendirin"
                ]
                estimated_time = "2-4 Saat"
            else:
                diagnosis = "ƒ∞zole Kritik Arƒ±za - Sadece bu aboneye √∂zel sorun."
                actions = [
                    "[ACƒ∞L] Saha ekibi g√∂revlendir",
                    "Bina giri≈üi fiber baƒülantƒ±sƒ±nƒ± kontrol et",
                    "Modem/ONT g√º√ß seviyelerini √∂l√ß (RX/TX power)",
                    "Gerekirse modem deƒüi≈üimi yap"
                ]
                estimated_time = "45-90 Dakika"
                
        elif request.current_status == "YELLOW":
            diagnosis = "Performans D√º≈ü√ºkl√ºƒü√º / Tƒ±kanƒ±klƒ±k tespit edildi."
            actions = [
                "Uzaktan hat testi yap (remote line test)",
                "SNR ve attenuation deƒüerlerini kontrol et"
            ]
            if scope == "REGIONAL":
                actions.append(f"B√∂lgesel y√ºk kontrol√º yap - {neighbor_faults} kom≈üu da etkilenmi≈ü")
                actions.append("Peak hour traffic analizi yapƒ±lmalƒ±")
            else:
                actions.append("M√º≈üteriye WiFi optimizasyonu √∂ner")
                actions.append("Modem firmware g√ºncellemesi kontrol et")
            estimated_time = "30-60 Dakika"
            
        else:  # GREEN
            diagnosis = "Abone hattƒ± stabil g√∂r√ºn√ºyor, m√º≈üteri ≈üikayeti ara≈ütƒ±rƒ±lmalƒ±."
            actions = [
                "M√º≈üteriyle ileti≈üime ge√ß - ≈üikayet detayƒ±nƒ± √∂ƒüren",
                "Belirli uygulamalar i√ßin sorun mu var kontrol et",
                "Cihaz/WiFi seviyesinde sorun olabilir"
            ]
            estimated_time = "15-30 Dakika"
        
        # 7. Structured Response
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
        
        return {
            "scope": scope,
            "neighbor_count": neighbor_faults,
            "header": {
                "timestamp": timestamp,
                "subscriber_id": request.subscriber_id,
                "region": region_id,
                "modem": modem_model,
                "priority": priority,
                "status": status_tr.get(request.current_status, 'UNKNOWN'),
                "status_icon": status_icon
            },
            "metrics": metrics_data,
            "diagnosis": {
                "text": diagnosis,
                "ai_analysis": request.ai_analysis,
                "estimated_time": estimated_time
            },
            "actions": actions
        }

    except Exception as e:
        logger.error(f"Ticket Generation Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ===================================================================
# TICKET MANAGEMENT ENDPOINTS
# ===================================================================

class TicketCreate(BaseModel):
    subscriber_id: int
    priority: str  # HIGH, MEDIUM, LOW
    fault_type: str  # INFRASTRUCTURE, CPE, NETWORK
    scope: str  # REGIONAL, INDIVIDUAL
    technician_note: str
    assigned_to: Optional[str] = "Teknisyen Ekibi"

class TicketStatusUpdate(BaseModel):
    new_status: str  # CREATED, ASSIGNED, EN_ROUTE, ON_SITE, RESOLVED, CLOSED
    changed_by: str
    note: Optional[str] = None

class TechnicianNote(BaseModel):
    note: str
    author: str


@app.post("/api/tickets")
def create_ticket(ticket: TicketCreate):
    """
    Yeni ticket olu≈üturur ve action_log'a kaydeder.
    """
    try:
        conn = get_db_connection()
        if not conn:
            raise HTTPException(status_code=500, detail="Database connection failed")
        
        cursor = conn.cursor()
        
        # 1. Ticket olu≈ütur
        cursor.execute("""
            INSERT INTO tickets 
            (subscriber_id, status, priority, fault_type, scope, technician_note, assigned_to)
            VALUES (%s, %s, %s, %s, %s, %s, %s)
            RETURNING ticket_id, created_at
        """, (
            ticket.subscriber_id,
            'CREATED',
            ticket.priority,
            ticket.fault_type,
            ticket.scope,
            ticket.technician_note,
            ticket.assigned_to
        ))
        
        ticket_id, created_at = cursor.fetchone()
        
        # 2. ƒ∞lk status history kaydƒ±
        cursor.execute("""
            INSERT INTO ticket_status_history
            (ticket_id, old_status, new_status, changed_by, note)
            VALUES (%s, %s, %s, %s, %s)
        """, (ticket_id, None, 'CREATED', 'System', f'Ticket olu≈üturuldu - {ticket.assigned_to}'))
        
        # 3. Action log'a kaydet
        cursor.execute("""
            INSERT INTO action_log 
            (subscriber_id, action_type, new_status, note, timestamp)
            VALUES (%s, %s, %s, %s, NOW())
        """, (
            ticket.subscriber_id,
            'ticket_created',
            ticket.priority,
            f'Arƒ±za kaydƒ± #{ticket_id} olu≈üturuldu - {ticket.scope} arƒ±za'
        ))
        
        conn.commit()
        cursor.close()
        conn.close()
        
        return {
            "success": True,
            "ticket_id": ticket_id,
            "status": "CREATED",
            "created_at": created_at.isoformat()
        }
        
    except Exception as e:
        logger.error(f"‚ùå Ticket Creation Error: {e}")
        import traceback
        traceback.print_exc()
        if conn:
            conn.close()
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/tickets/{subscriber_id}")
def get_subscriber_tickets(subscriber_id: int):
    """
    Bir abone'nin t√ºm ticketlarƒ±nƒ± getirir (son 30 g√ºn).
    """
    try:
        conn = get_db_connection()
        if not conn:
            raise HTTPException(status_code=500, detail="Database fail")
        
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT 
                ticket_id, status, priority, fault_type, scope,
                assigned_to, created_at, updated_at, resolved_at
            FROM tickets
            WHERE subscriber_id = %s
            AND created_at >= NOW() - INTERVAL '30 days'
            ORDER BY created_at DESC
        """, (subscriber_id,))
        
        rows = cursor.fetchall()
        cursor.close()
        conn.close()
        
        tickets = []
        for row in rows:
            tickets.append({
                "ticket_id": row[0],
                "status": row[1],
                "priority": row[2],
                "fault_type": row[3],
                "scope": row[4],
                "assigned_to": row[5],
                "created_at": row[6].isoformat(),
                "updated_at": row[7].isoformat() if row[7] else None,
                "resolved_at": row[8].isoformat() if row[8] else None
            })
        
        return {"tickets": tickets}
        
    except Exception as e:
        logger.error(f"Get Tickets Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/tickets")
def get_all_tickets(status: Optional[str] = None, limit: int = 50):
    """
    T√ºm ticketlarƒ± getirir (saha ekibi paneli i√ßin).
    Status filtresi opsiyonel.
    """
    try:
        conn = get_db_connection()
        if not conn:
            raise HTTPException(status_code=500, detail="Database fail")
        
        cursor = conn.cursor()
        
        if status:
            query = """
                SELECT 
                    t.ticket_id, t.subscriber_id, t.status, t.priority, 
                    t.fault_type, t.scope, t.assigned_to, t.created_at,
                    c.full_name, c.region_id, c.phone_number
                FROM tickets t
                LEFT JOIN customers c ON t.subscriber_id = c.subscriber_id
                WHERE t.status = %s
                ORDER BY 
                    CASE t.priority
                        WHEN 'HIGH' THEN 1
                        WHEN 'MEDIUM' THEN 2
                        WHEN 'LOW' THEN 3
                    END,
                    t.created_at DESC
                LIMIT %s
            """
            cursor.execute(query, (status, limit))
        else:
            query = """
                SELECT 
                    t.ticket_id, t.subscriber_id, t.status, t.priority, 
                    t.fault_type, t.scope, t.assigned_to, t.created_at,
                    c.full_name, c.region_id, c.phone_number
                FROM tickets t
                LEFT JOIN customers c ON t.subscriber_id = c.subscriber_id
                WHERE t.status != 'CLOSED'
                ORDER BY 
                    CASE t.priority
                        WHEN 'HIGH' THEN 1
                        WHEN 'MEDIUM' THEN 2
                        WHEN 'LOW' THEN 3
                    END,
                    t.created_at DESC
                LIMIT %s
            """
            cursor.execute(query, (limit,))
        
        rows = cursor.fetchall()
        cursor.close()
        conn.close()
        
        tickets = []
        for row in rows:
            tickets.append({
                "ticket_id": row[0],
                "subscriber_id": row[1],
                "status": row[2],
                "priority": row[3],
                "fault_type": row[4],
                "scope": row[5],
                "assigned_to": row[6],
                "created_at": row[7].isoformat(),
                "customer_name": row[8],
                "customer_location": row[9],
                "customer_phone": row[10]
            })
        
        return {"tickets": tickets, "count": len(tickets)}
        
    except Exception as e:
        logger.error(f"Get All Tickets Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.patch("/api/tickets/{ticket_id}/status")
def update_ticket_status(ticket_id: int, update: TicketStatusUpdate):
    """
    Ticket status'unu g√ºnceller ve action_log'a kaydeder.
    """
    try:
        conn = get_db_connection()
        if not conn:
            raise HTTPException(status_code=500, detail="Database fail")
        
        cursor = conn.cursor()
        
        # 1. Mevcut status'u al
        cursor.execute("SELECT status, subscriber_id FROM tickets WHERE ticket_id = %s", (ticket_id,))
        result = cursor.fetchone()
        
        if not result:
            raise HTTPException(status_code=404, detail="Ticket not found")
        
        old_status, subscriber_id = result
        
        # 2. Status g√ºncelle
        if update.new_status == 'RESOLVED':
            cursor.execute("""
                UPDATE tickets 
                SET status = %s, updated_at = NOW(), resolved_at = NOW()
                WHERE ticket_id = %s
            """, (update.new_status, ticket_id))
        else:
            cursor.execute("""
                UPDATE tickets 
                SET status = %s, updated_at = NOW()
                WHERE ticket_id = %s
            """, (update.new_status, ticket_id))
        
        # 3. Status history ekle
        cursor.execute("""
            INSERT INTO ticket_status_history
            (ticket_id, old_status, new_status, changed_by, note)
            VALUES (%s, %s, %s, %s, %s)
        """, (ticket_id, old_status, update.new_status, update.changed_by, update.note))
        
        # 4. Action log ekle
        status_translations = {
            'CREATED': 'Olu≈üturuldu',
            'ASSIGNED': 'Atandƒ±',
            'EN_ROUTE': 'Yolda',
            'ON_SITE': 'Sahada',
            'RESOLVED': '√á√∂z√ºld√º',
            'CLOSED': 'Kapatƒ±ldƒ±'
        }
        
        log_note = f"Ticket #{ticket_id} - {status_translations.get(old_status, old_status)} ‚Üí {status_translations.get(update.new_status, update.new_status)}"
        if update.note:
            log_note += f" | {update.note}"
        
        cursor.execute("""
            INSERT INTO action_log 
            (subscriber_id, action_type, new_status, note, timestamp)
            VALUES (%s, %s, %s, %s, NOW())
        """, (subscriber_id, 'ticket_status_update', update.new_status, log_note))
        
        conn.commit()
        cursor.close()
        conn.close()
        
        return {
            "success": True,
            "ticket_id": ticket_id,
            "old_status": old_status,
            "new_status": update.new_status
        }
        
    except HTTPException as he:
        raise he
    except Exception as e:
        logger.error(f"Update Ticket Status Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/tickets/{ticket_id}/note")
def add_technician_note(ticket_id: int, note_data: TechnicianNote):
    """
    Teknisyen notu ekler ve action_log'a kaydeder.
    """
    try:
        conn = get_db_connection()
        if not conn:
            raise HTTPException(status_code=500, detail="Database fail")
        
        cursor = conn.cursor()
        
        # 1. Ticket var mƒ± kontrol et
        cursor.execute("SELECT subscriber_id, technician_note FROM tickets WHERE ticket_id = %s", (ticket_id,))
        result = cursor.fetchone()
        
        if not result:
            raise HTTPException(status_code=404, detail="Ticket not found")
        
        subscriber_id, existing_note = result
        
        # 2. Notu ekle (mevcut nota append)
        updated_note = f"{existing_note}\n\n--- {note_data.author} ({datetime.now().strftime('%Y-%m-%d %H:%M')}) ---\n{note_data.note}"
        
        cursor.execute("""
            UPDATE tickets 
            SET technician_note = %s, updated_at = NOW()
            WHERE ticket_id = %s
        """, (updated_note, ticket_id))
        
        # 3. Action log ekle
        cursor.execute("""
            INSERT INTO action_log 
            (subscriber_id, action_type, new_status, note, timestamp)
            VALUES (%s, %s, %s, %s, NOW())
        """, (subscriber_id, 'technician_note_added', 'INFO', f"Ticket #{ticket_id} - {note_data.author}: {note_data.note[:50]}..."))
        
        conn.commit()
        cursor.close()
        conn.close()
        
        return {"success": True, "ticket_id": ticket_id}
        
    except HTTPException as he:
        raise he
    except Exception as e:
        logger.error(f"Add Note Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

