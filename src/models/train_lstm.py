import pandas as pd
import numpy as np
import joblib
import os
# TensorFlow uyarÄ±larÄ±nÄ± gizleyelim (Kafa karÄ±ÅŸtÄ±rmasÄ±n)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from sklearn.model_selection import train_test_split

# --- AYARLAR ---
# Dosya yollarÄ±nÄ± dinamik bul
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
DATA_PATH = os.path.join(BASE_DIR, 'data', 'netpulse_telemetry_final.csv')
MODEL_DIR = os.path.join(BASE_DIR, 'src', 'models', 'saved_objects')

# KlasÃ¶r yoksa oluÅŸtur
os.makedirs(MODEL_DIR, exist_ok=True)

print(f"ğŸš€ LSTM (Zaman Serisi) EÄŸitimi BaÅŸlÄ±yor...\nğŸ“‚ Veri Yolu: {DATA_PATH}")

def train_lstm_model():
    # 1. VERÄ°YÄ° YÃœKLE
    if not os.path.exists(DATA_PATH):
        print("âŒ HATA: CSV dosyasÄ± bulunamadÄ±! LÃ¼tfen Ã¶nce veri Ã¼retin.")
        return

    df = pd.read_csv(DATA_PATH)
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    df = df.sort_values('timestamp') # Zaman sÄ±rasÄ±na dizmek ÅART!

    # Sadece Region_1 verisini alalÄ±m (EÄŸitim net olsun)
    df_sample = df[df['region_id'] == 'Region_1'].copy()
    
    print(f"ğŸ“Š Veri HazÄ±r: {len(df_sample)} satÄ±r zaman serisi iÅŸleniyor.")

    # 2. Ã–ZELLÄ°KLERÄ° HAZIRLA
    features = ['latency_ms', 'packet_loss_ratio', 'snr_margin_db', 'download_usage_mbps']
    
    # Hedefi SayÄ±ya Ã‡evir (ArÄ±za TÃ¼rleri: 0, 1, 2...)
    encoder = LabelEncoder()
    df_sample['root_cause_code'] = encoder.fit_transform(df_sample['root_cause'])
    
    # Verileri 0-1 arasÄ±na sÄ±kÄ±ÅŸtÄ±r (LSTM, kÃ¼Ã§Ã¼k sayÄ±larÄ± sever)
    scaler = MinMaxScaler()
    data_scaled = scaler.fit_transform(df_sample[features])

    # 3. ZAMAN PENCERESÄ° (Sliding Window)
    # MantÄ±k: GeÃ§miÅŸ 12 veriye bak (1 saat) -> Gelecek durumu tahmin et.
    X, y = [], []
    window_size = 12 

    for i in range(window_size, len(data_scaled)):
        X.append(data_scaled[i-window_size:i]) # GeÃ§miÅŸ 12 adÄ±m (Girdi)
        y.append(df_sample['root_cause_code'].iloc[i]) # Åu anki durum (Ã‡Ä±ktÄ±)

    X, y = np.array(X), np.array(y)

    # %80 EÄŸitim, %20 Test
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

    print(f"ğŸ§  Model TasarlanÄ±yor... (Girdi Åekli: {X_train.shape})")

    # 4. LSTM MODELÄ°NÄ° KUR (YAPAY SÄ°NÄ°R AÄI)
    model = Sequential()
    # Katman 1: LSTM (HafÄ±za HÃ¼cresi)
    model.add(LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
    model.add(Dropout(0.2)) # Ezberlemeyi Ã¶nle
    
    # Katman 2: LSTM
    model.add(LSTM(32, return_sequences=False))
    model.add(Dropout(0.2))
    
    # Ã‡Ä±ktÄ± KatmanÄ±: KaÃ§ Ã§eÅŸit arÄ±za varsa o kadar Ã§Ä±kÄ±ÅŸ ver
    num_classes = len(np.unique(y))
    model.add(Dense(num_classes, activation='softmax'))

    # Modeli Derle
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    # 5. EÄÄ°TÄ°MÄ° BAÅLAT
    print("â³ EÄŸitim baÅŸladÄ±... (BilgisayarÄ±n fanlarÄ± biraz Ã§alÄ±ÅŸabilir!)")
    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))

    # 6. KAYDET
    model.save(os.path.join(MODEL_DIR, 'netpulse_lstm.h5'))
    joblib.dump(scaler, os.path.join(MODEL_DIR, 'lstm_scaler.pkl'))
    joblib.dump(encoder, os.path.join(MODEL_DIR, 'lstm_encoder.pkl'))

    print("\n" + "="*50)
    print(f"âœ… TEBRÄ°KLER! GeleceÄŸi GÃ¶ren Model (LSTM) Kaydedildi.")
    print(f"ğŸ“‚ Yer: {MODEL_DIR}")
    print("="*50)

if __name__ == "__main__":
    train_lstm_model()